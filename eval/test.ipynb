{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b89c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Markdown\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece68cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Workspace\\viettel\\mini-project\\eval\\eval-agent-sql\\eval\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "import os\n",
    "from phoenix.otel import register\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from openinference.semconv.trace import SpanAttributes\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "from openinference.instrumentation import TracerProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2706f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:142: SAWarning: Skipped unsupported reflection of expression-based index ix_cumulative_llm_token_count_total\n",
      "  next(self.gen)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:142: SAWarning: Skipped unsupported reflection of expression-based index ix_latency\n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://arize.com/docs/phoenix\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "\n",
    "session = px.launch_app()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0817e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenTelemetry Tracing Details\n",
      "|  Phoenix Project: sql-agent\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://localhost:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from phoenix.otel import register\n",
    "\n",
    "tracer_provider = register(\n",
    "  project_name=\"sql-agent\",\n",
    "  endpoint=\"http://localhost:6006/v1/traces\",\n",
    "  protocol=\"grpc\",\n",
    "  \n",
    ")\n",
    "OpenAIInstrumentor().instrument(tracer_provider = tracer_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5febeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer = tracer_provider.get_tracer(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff09fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template for step 2 of tool 1\n",
    "SQL_GENERATION_PROMPT = \"\"\"\n",
    "Generate an SQL query based on a prompt\",\" Do not reply with anything besides the SQL query\",\"\n",
    "The prompt is: {prompt}\n",
    "\n",
    "The SQL query should be valid and executable on a PostgreSQL database\",\"\n",
    "The database schema is as follows:\n",
    "{schema}\n",
    "Only Select statements are allowed\",\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a52658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI()\n",
    "\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519fd221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for step 2 of tool 1\n",
    "@tracer.chain()\n",
    "def generate_sql_query(prompt: str, schema: str) -> str:\n",
    "    \"\"\"Generate an SQL query based on a prompt\"\"\"\n",
    "    formatted_prompt = SQL_GENERATION_PROMPT.format(prompt=prompt, \n",
    "                                                    schema=schema)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d218579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for tool 1\n",
    "@tracer.tool()\n",
    "def lookup_sales_data(prompt: str) -> str:\n",
    "    \"\"\"Implementation of data lookup from postgres db using SQL\"\"\"\n",
    "    try:\n",
    "        import requests\n",
    "        with tracer.start_as_current_span(\"prompt for retrieving schema context\",openinference_span_kind=\"chain\") as span:\n",
    "            span.set_input(prompt)\n",
    "            # Step 1: Get schema context from the context endpoint\n",
    "            context_response = requests.post(\n",
    "                \"http://localhost:8000/context\",\n",
    "                json={\"query\": prompt}  # Fixed: prompt is now the direct value\",\" not inside another dict\n",
    "            )\n",
    "            \n",
    "            if context_response.status_code != 200:\n",
    "                return f\"Error retrieving schema context: {context_response.text}\"\n",
    "            \n",
    "            context_data = context_response.json()\n",
    "            # Extract text from contexts to use as schema\n",
    "            schema = context_data.get(\"contexts\", [])\n",
    "            span.set_output(value=schema)\n",
    "        # Step 2: Generate SQL query based on prompt and schema\n",
    "        sql_query = generate_sql_query(prompt, schema)\n",
    "        print(f\"Generated SQL Query: {sql_query}\")  # Debugging output\n",
    "        # Clean the response to make sure it only includes the SQL code\n",
    "        sql_query = sql_query.strip()\n",
    "        sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
    "        \n",
    "        # Step 3: Execute the SQL query using the data endpoint\n",
    "        data_response = requests.post(\n",
    "            \"http://localhost:8000/data\",\n",
    "            json={\"query\": sql_query}\n",
    "        )\n",
    "        \n",
    "        if data_response.status_code != 200:\n",
    "            return f\"Error executing query: {data_response.text}\"\n",
    "        \n",
    "        # Convert the response to a pandas DataFrame for formatting\n",
    "        result_data = data_response.json()\n",
    "        if not result_data[\"records\"]:\n",
    "            return \"No results found for your query.\"\n",
    "            \n",
    "        result = pd.DataFrame(result_data[\"records\"])\n",
    "        \n",
    "        return result.to_string()\n",
    "    except Exception as e:\n",
    "        return f\"Error accessing data: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b94aca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_data = lookup_sales_data(\"Ti·ªÅn ph·∫°t c·ªßa t·ªânh AGG nƒÉm 2024 theo t·ª´ng th√°ng l√† bao nhi√™u\")\n",
    "# print(example_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc9b4e",
   "metadata": {},
   "source": [
    "# Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b6c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools/functions that can be called by the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_sales_data\",\n",
    "            \"description\": \"Look up data from postgres database using SQL\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided\",\"\"}\n",
    "                },\n",
    "                \"required\": [\"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Dictionary mapping function names to their implementations\n",
    "tool_implementations = {\n",
    "    \"lookup_sales_data\": lookup_sales_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c15406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for executing the tools returned in the model's response\n",
    "@tracer.chain()\n",
    "def handle_tool_calls(tool_calls, messages):\n",
    "    \n",
    "    for tool_call in tool_calls:   \n",
    "        function = tool_implementations[tool_call.function.name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        result = function(**function_args)\n",
    "        messages.append({\"role\": \"tool\", \"content\": result, \"tool_call_id\": tool_call.id})\n",
    "        \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac04c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that can answer questions about data and generate visualizations using tools\",\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12519c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(messages):\n",
    "    print(\"Running agent with messages:\", messages)\n",
    "    if isinstance(messages, str):\n",
    "        messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "    if not any(\n",
    "            isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n",
    "        ):\n",
    "            system_prompt = {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n",
    "            messages.append(system_prompt)\n",
    "\n",
    "    while True:\n",
    "        # Router Span\n",
    "        print(\"Starting router call span\")\n",
    "        with tracer.start_as_current_span(\n",
    "            \"router_call\", openinference_span_kind=\"chain\",\n",
    "        ) as span:\n",
    "            span.set_input(value=messages)\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "            )\n",
    "            messages.append(response.choices[0].message.model_dump())\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "            print(\"Received response with tool calls:\", bool(tool_calls))\n",
    "            span.set_status(StatusCode.OK)\n",
    "    \n",
    "            if tool_calls:\n",
    "                print(\"Starting tool calls span\")\n",
    "                messages = handle_tool_calls(tool_calls, messages)\n",
    "                span.set_output(value=tool_calls)\n",
    "            else:\n",
    "                print(\"No tool calls, returning final response\")\n",
    "                span.set_output(value=response.choices[0].message.content)\n",
    "                return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c96a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_main_span(messages):\n",
    "    print(\"Starting main span with messages:\", messages)\n",
    "    \n",
    "    with tracer.start_as_current_span(\n",
    "        \"AgentRun\", openinference_span_kind=\"agent\"\n",
    "    ) as span:\n",
    "        span.set_input(value=messages)\n",
    "        ret = run_agent(messages)\n",
    "        print(\"Main span completed with return value:\", ret)\n",
    "        span.set_output(value=ret)\n",
    "        span.set_status(StatusCode.OK)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3a35f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: [{'role': 'user', 'content': 'Ti·ªÅn ph·∫°t c·ªßa t·ªânh AGG nƒÉm 2024 theo t·ª´ng th√°ng l√† bao nhi√™u'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Ti·ªÅn ph·∫°t c·ªßa t·ªânh AGG nƒÉm 2024 theo t·ª´ng th√°ng l√† bao nhi√™u'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Starting tool calls span\n",
      "Generated SQL Query: ```sql\n",
      "SELECT\n",
      "    thang,\n",
      "    SUM(tong_phat) AS tong_tien_phat\n",
      "FROM\n",
      "    public.\"vcc_vhkt.vhkt_import_dt_tp_vtt_2\"\n",
      "WHERE\n",
      "    nam = 2024\n",
      "    AND ma_tinh = 'AGG'\n",
      "GROUP BY\n",
      "    thang\n",
      "ORDER BY\n",
      "    thang;\n",
      "```\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n",
      "Main span completed with return value: D∆∞·ªõi ƒë√¢y l√† ti·ªÅn ph·∫°t c·ªßa t·ªânh AGG nƒÉm 2024 theo t·ª´ng th√°ng:\n",
      "\n",
      "| Th√°ng | T·ªïng Ti·ªÅn Ph·∫°t (VNƒê)    |\n",
      "|-------|-------------------------|\n",
      "| 1     | 30,166,750,000          |\n",
      "| 2     | 8,531,815,000           |\n",
      "| 3     | 4,670,423,000           |\n",
      "| 4     | 5,558,362,000           |\n",
      "| 5     | 8,451,318,000           |\n",
      "| 6     | 3,086,113,000           |\n",
      "| 7     | 9,217,955,000           |\n",
      "| 8     | 21,429,060,000          |\n",
      "| 9     | 30,370,300,000          |\n",
      "| 10    | 22,404,570,000          |\n",
      "| 11    | 18,241,920,000          |\n",
      "| 12    | 19,267,380,000          |\n",
      "\n",
      "N·∫øu b·∫°n c·∫ßn th√™m th√¥ng tin hay ph√¢n t√≠ch n√†o kh√°c, h√£y cho t√¥i bi·∫øt!\n"
     ]
    }
   ],
   "source": [
    "result = start_main_span([{\"role\": \"user\", \n",
    "                           \"content\": \"Ti·ªÅn ph·∫°t c·ªßa t·ªânh AGG nƒÉm 2024 theo t·ª´ng th√°ng l√† bao nhi√™u\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac57a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions:   0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SQL Query: ```sql\n",
      "SELECT \n",
      "    thang, \n",
      "    AVG(ty_le_pakh_10000tb_ngay_dich_vu_ftth) AS ty_le_pakh_ftth, \n",
      "    AVG(ty_le_pakh_10000tb_ngay_dich_vu_khac) AS ty_le_pakh_khac\n",
      "FROM \n",
      "    public.\"vcc_vhkt.vhkt_import_kpi_duy_tri_cdbr_tinh\"\n",
      "WHERE \n",
      "    nam = 2024\n",
      "GROUP BY \n",
      "    thang\n",
      "ORDER BY \n",
      "    thang;\n",
      "```\n",
      "Error processing question: T·ª∑ l·ªá PAKH to√†n qu·ªëc trong nƒÉm 2024 theo t·ª´ng th√°ng l√† bao nhi√™u\n",
      "object str can't be used in 'await' expression\n",
      "Generated SQL Query: ```sql\n",
      "SELECT \n",
      "    SUM(tong_su_co_phat_sinh_co_hen) AS tong_su_co_phat_sinh_co_hen,\n",
      "    SUM(tong_su_co_duoc_xu_ly_dung_hen) AS tong_su_co_duoc_xu_ly_dung_hen,\n",
      "    (SUM(tong_su_co_duoc_xu_ly_dung_hen) * 100.0 / NULLIF(SUM(tong_su_co_phat_sinh_co_hen), 0)) AS ty_le_su_co_duoc_xu_ly_dung_hen\n",
      "FROM \n",
      "    public.\"vcc_vhkt.vhkt_import_kpi_duy_tri_cdbr_tinh\"\n",
      "WHERE \n",
      "    nam = 2024;\n",
      "```\n",
      "Error processing question: T·ª∑ l·ªá s·ª± c·ªë l·∫∑p l·∫°i to√†n qu·ªëc trong nƒÉm 2024 l√† bao nhi√™u\n",
      "object str can't be used in 'await' expression\n",
      "Generated SQL Query: ```sql\n",
      "SELECT \n",
      "    SUM(tong_su_co_da_xu_ly_trong_thang) AS tong_su_co_da_xu_ly,\n",
      "    SUM(tong_su_co_phat_sinh_co_hen) AS tong_su_co_phat_sinh_co_hen,\n",
      "    (SUM(tong_su_co_phat_sinh_co_hen) FILTER (WHERE tong_su_co_phat_sinh_co_hen > 0) * 100.0 / NULLIF(SUM(tong_su_co_da_xu_ly_trong_thang), 0)) AS ty_le_su_co_lap_lai\n",
      "FROM \n",
      "    public.\"vcc_vhkt.vhkt_import_kpi_duy_tri_cdbr_tinh\"\n",
      "WHERE \n",
      "    nam = 2024;\n",
      "```\n",
      "Error processing question: T·ª∑ l·ªá s·ª± c·ªë l·∫∑p l·∫°i to√†n qu·ªëc trong nƒÉm 2024 l√† bao nhi√™u\n",
      "object str can't be used in 'await' expression\n",
      "Generated SQL Query: ```sql\n",
      "SELECT thang,\n",
      "       COUNT(*) FILTER (WHERE so_phan_anh_phat_sinh_trong_thang_dich_vu_ftth + so_phan_anh_phat_sinh_trong_thang_dich_vu_khac > 0) AS so_su_co_lap_lai,\n",
      "       SUM(COALESCE(so_phan_anh_phat_sinh_trong_thang_dich_vu_ftth + so_phan_anh_phat_sinh_trang_thang_dich_vu_khac, 0)) AS tong_so_su_co,\n",
      "       (COUNT(*) FILTER (WHERE so_phan_anh_phat_sinh_trong_thang_dich_vu_ftth + so_phan_anh_phat_sinh_trong_thang_dich_vu_khac > 0) * 100.0 / NULLIF(SUM(COALESCE(so_phan_anh_phat_sinh_trong_thang_dich_vu_ftth + so_phan_anh_phat_sinh_trong_thang_dich_vu_khac, 0), 0)) AS ty_le_su_co_lap_lai\n",
      "FROM public.\"vcc_vhkt.vhkt_import_kpi_duy_tri_cdbr_huyen\"\n",
      "WHERE nam = 2024\n",
      "GROUP BY thang\n",
      "ORDER BY thang;\n",
      "```\n",
      "Error processing question: T·ª∑ l·ªá s·ª± c·ªë l·∫∑p l·∫°i to√†n qu·ªëc trong nƒÉm 2024 theo t·ª´ng th√°ng l√† bao nhi√™u\n",
      "object str can't be used in 'await' expression\n",
      "Generated SQL Query: ```sql\n",
      "SELECT \n",
      "    AVG(ty_le_thuc_hien_su_co_chu_dong_trong_10h_phan_tram) AS ty_le_su_co_lap_lai\n",
      "FROM \n",
      "    public.\"vcc_vhkt.vhkt_import_kpi_duy_tri_cdbr_tinh\" \n",
      "WHERE \n",
      "    nam = 2024\n",
      "    AND khu_vuc = 'AGG';\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from tqdm import tqdm\n",
    "agent_questions = [\n",
    "    \"T·ªïng ti·ªÅn ph·∫°t nƒÉm 2024 l√† bao nhi√™u\",\n",
    "    \"T·ªïng ti·ªÅn ph·∫°t c·ªßa t·ªânh AGG nƒÉm 2024 l√† bao nhi√™u\",\n",
    "    \"Ti·ªÅn ph·∫°t c·ªßa t·ªânh AGG theo t·ª´ng th√°ng nƒÉm 2024\",\n",
    "    \"Ti·ªÅn ph·∫°t KPI duy tr√¨ c·ªßa AGG nƒÉm 2024 l√† bao nhi√™u\",\n",
    "    \"Ti·ªÅn ph·∫°t KPI duy tr√¨ c·ªßa AGG theo t·ª´ng th√°ng nƒÉm 2024\",\n",
    "    \"Ti·ªÅn ph·∫°t KPI tri·ªÉn khai m·ªõi c·ªßa AGG nƒÉm 2024 l√† bao nhi√™u\",\n",
    "    \"Ti·ªÅn ph·∫°t KPI tri·ªÉn khai m·ªõi c·ªßa AGG theo t·ª´ng th√°ng nƒÉm 2024\",\n",
    "    \"Ti·ªÅn ph·∫°t l·ªói √Ω th·ª©c, th√°i ƒë·ªô c·ªßa AGG nƒÉm 2024 l√† bao nhi√™u\",\n",
    "    \"Ti·ªÅn ph·∫°t l·ªói √Ω th·ª©c th√°i ƒë·ªô c·ªßa AGG theo t·ª´ng th√°ng nƒÉm 2024\",\n",
    "    \"Ti·ªÅn ph·∫°t r·ªùi m·∫°ng c·ªßa AGG nƒÉm 2024 l√† bao nhi√™u\",\n",
    "    \"Ti·ªÅn ph·∫°t r·ªùi m·∫°ng c·ªßa AGG theo t·ª´ng th√°ng nƒÉm 2024\",\n",
    "    \"T·ª∑ l·ªá PAKH to√†n qu·ªëc trong nƒÉm 2024 l√† bao nhi√™u\",\n",
    "    \"T·ª∑ l·ªá PAKH to√†n qu·ªëc trong nƒÉm 2024 theo t·ª´ng th√°ng l√† bao nhi√™u\",\n",
    "  \"T·ª∑ l·ªá s·ª± c·ªë l·∫∑p l·∫°i to√†n qu·ªëc trong nƒÉm 2024 l√† bao nhi√™u\",\n",
    "    \"T·ª∑ l·ªá s·ª± c·ªë l·∫∑p l·∫°i to√†n qu·ªëc trong nƒÉm 2024 theo t·ª´ng th√°ng l√† bao nhi√™u\",\n",
    "    \"T·ª∑ l·ªá s·ª± c·ªë l·∫∑p l·∫°i to√†n qu·ªëc trong nƒÉm 2024 l√† bao nhi√™u\",\n",
    "    \"T·ª∑ l·ªá s·ª± c·ªë l·∫∑p l·∫°i to√†n qu·ªëc trong nƒÉm 2024 theo t·ª´ng th√°ng l√† bao nhi√™u\",\n",
    "    \"T·ª∑ l·ªá s·ª± c·ªë l·∫∑p l·∫°i c·ªßa AGG nƒÉm 2024 l√† bao nhi√™u\",\n",
    "    \"T·ª∑ l·ªá s·ª± c·ªë l·∫∑p l·∫°i c·ªßa AGG nƒÉm 2024 theo t·ª´ng th√°ng l√† bao nhi√™u?\",\n",
    "    \"S·ªë PAKH ph√°t sinh nƒÉm 2024 theo t·ª´ng th√°ng l√† bao nhi√™u?\",\n",
    "    \"T·ª∑ l·ªá x·ª≠ l√Ω s·ª± c·ªë trong 3h nƒÉm 2024 c·ªßa To√†n qu·ªëc theo t·ª´ng th√°ng l√† bao nhi√™u?\",\n",
    "    \"S·ªë l∆∞·ª£ng s·ª± c·ªë ph√°t sinh c·ªßa AGG nƒÉm 2024 theo t·ª´ng th√°ng l√† bao nhi√™u?\",\n",
    "    # \"T·ª∑ l·ªá x·ª≠ l√Ω s·ª± c·ªë trong 10h nƒÉm 2024 c·ªßa To√†n qu·ªëc l√† bao nhi√™u?\",\n",
    "\n",
    "]\n",
    "\n",
    "for question in tqdm(agent_questions, desc=\"Processing questions\"):\n",
    "\n",
    "    try:\n",
    "        ret= lookup_sales_data(question)\n",
    "        # print(f\"Result for question '{question}':\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing question: {question}\")\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8890a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals import (\n",
    "    TOOL_CALLING_PROMPT_TEMPLATE, \n",
    "    llm_classify,\n",
    "    OpenAIModel\n",
    ")\n",
    "from phoenix.trace import SpanEvaluations\n",
    "from phoenix.trace.dsl import SpanQuery\n",
    "from openinference.instrumentation import suppress_tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c75fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sql_gen</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>715fd7cdad76baed</th>\n",
       "      <td>```sql\\nSELECT SUM(tong_phat) AS tong_tien_pha...</td>\n",
       "      <td>{\"prompt\": \"T·ªïng ti·ªÅn ph·∫°t nƒÉm 2024\", \"schema\"...</td>\n",
       "      <td>[{\"role\": \"user\", \"content\": \"T·ªïng ti·ªÅn ph·∫°t n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca196ca3dd66c0db</th>\n",
       "      <td>```sql\\nSELECT SUM(tong_phat) AS tong_tien_pha...</td>\n",
       "      <td>{\"prompt\": \"T·ªïng ti·ªÅn ph·∫°t c·ªßa t·ªânh AGG nƒÉm 20...</td>\n",
       "      <td>[{\"role\": \"user\", \"content\": \"T·ªïng ti·ªÅn ph·∫°t c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08394cc649b3b987</th>\n",
       "      <td>```sql\\nSELECT thang, SUM(tong_phat) AS tong_t...</td>\n",
       "      <td>{\"prompt\": \"Ti·ªÅn ph·∫°t c·ªßa t·ªânh AGG theo t·ª´ng t...</td>\n",
       "      <td>[{\"role\": \"user\", \"content\": \"Ti·ªÅn ph·∫°t c·ªßa t·ªâ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4aeb95b07ed2be60</th>\n",
       "      <td>```sql\\nSELECT \\n    SUM(phat_kpi_duy_tri_cdbr...</td>\n",
       "      <td>{\"prompt\": \"Ti·ªÅn ph·∫°t KPI duy tr√¨ c·ªßa AGG nƒÉm ...</td>\n",
       "      <td>[{\"role\": \"user\", \"content\": \"Ti·ªÅn ph·∫°t KPI du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e8cad356d2362fe5</th>\n",
       "      <td>```sql\\nSELECT thang, SUM(phat_kpi_duy_tri_cdb...</td>\n",
       "      <td>{\"prompt\": \"Ti·ªÅn ph·∫°t KPI duy tr√¨ c·ªßa AGG theo...</td>\n",
       "      <td>[{\"role\": \"user\", \"content\": \"Ti·ªÅn ph·∫°t KPI du...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            sql_gen  \\\n",
       "context.span_id                                                       \n",
       "715fd7cdad76baed  ```sql\\nSELECT SUM(tong_phat) AS tong_tien_pha...   \n",
       "ca196ca3dd66c0db  ```sql\\nSELECT SUM(tong_phat) AS tong_tien_pha...   \n",
       "08394cc649b3b987  ```sql\\nSELECT thang, SUM(tong_phat) AS tong_t...   \n",
       "4aeb95b07ed2be60  ```sql\\nSELECT \\n    SUM(phat_kpi_duy_tri_cdbr...   \n",
       "e8cad356d2362fe5  ```sql\\nSELECT thang, SUM(phat_kpi_duy_tri_cdb...   \n",
       "\n",
       "                                                            context  \\\n",
       "context.span_id                                                       \n",
       "715fd7cdad76baed  {\"prompt\": \"T·ªïng ti·ªÅn ph·∫°t nƒÉm 2024\", \"schema\"...   \n",
       "ca196ca3dd66c0db  {\"prompt\": \"T·ªïng ti·ªÅn ph·∫°t c·ªßa t·ªânh AGG nƒÉm 20...   \n",
       "08394cc649b3b987  {\"prompt\": \"Ti·ªÅn ph·∫°t c·ªßa t·ªânh AGG theo t·ª´ng t...   \n",
       "4aeb95b07ed2be60  {\"prompt\": \"Ti·ªÅn ph·∫°t KPI duy tr√¨ c·ªßa AGG nƒÉm ...   \n",
       "e8cad356d2362fe5  {\"prompt\": \"Ti·ªÅn ph·∫°t KPI duy tr√¨ c·ªßa AGG theo...   \n",
       "\n",
       "                                                             prompt  \n",
       "context.span_id                                                      \n",
       "715fd7cdad76baed  [{\"role\": \"user\", \"content\": \"T·ªïng ti·ªÅn ph·∫°t n...  \n",
       "ca196ca3dd66c0db  [{\"role\": \"user\", \"content\": \"T·ªïng ti·ªÅn ph·∫°t c...  \n",
       "08394cc649b3b987  [{\"role\": \"user\", \"content\": \"Ti·ªÅn ph·∫°t c·ªßa t·ªâ...  \n",
       "4aeb95b07ed2be60  [{\"role\": \"user\", \"content\": \"Ti·ªÅn ph·∫°t KPI du...  \n",
       "e8cad356d2362fe5  [{\"role\": \"user\", \"content\": \"Ti·ªÅn ph·∫°t KPI du...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = SpanQuery().where(\n",
    "    \"name =='generate_sql_query'\"\n",
    ").select(\n",
    "    sql_gen=\"output.value\",\n",
    "    context=\"input.value\",\n",
    "    \n",
    ")\n",
    "prompt = SpanQuery().where(\n",
    "    \"span_kind=='AGENT'\"\n",
    ").select(\n",
    "    prompt=\"input.value\"\n",
    ")\n",
    "\n",
    "# The Phoenix Client can take this query and return the dataframe.\n",
    "sql_df = px.Client().query_spans(query, \n",
    "                                 project_name=\"sql-agent\",\n",
    "                                 timeout=None)\n",
    "\n",
    "prompt_df = px.Client().query_spans(prompt,\n",
    "                                    project_name=\"sql-agent\",\n",
    "                                    timeout=None)\n",
    "sql_df['prompt'] = prompt_df['prompt'].values\n",
    "sql_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80977ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sql_df to a file\n",
    "sql_df.to_csv(\"sql_queries.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1515c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to excel \n",
    "sql_df.to_excel(\"sql_queries2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf31550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
